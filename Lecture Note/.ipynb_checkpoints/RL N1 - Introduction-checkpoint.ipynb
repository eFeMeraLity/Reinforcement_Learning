{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RL N1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is RL different?\n",
    "\n",
    "* No supervisor, only a reward signal.\\\n",
    "没有监督，只有奖励信号。\n",
    "* Feedback is delayed, not instantaneous.\\\n",
    "反馈是延迟的，而不是瞬时的。\n",
    "* Time really matters (sequential, non i.i.d data)\\\n",
    "时间真的很重要（顺序的，非i.i.d数据）\n",
    "* Agent's actions affect the subsequent data it receives.\\\n",
    "agent的操作影响它接收到的后续数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the reward?\n",
    "\n",
    "Reward, $R_t$ : A scalar signal that tells agent how it is doing at step $t$.\\\n",
    "奖励$R_t$：一个标量信号，它告诉agent在步骤$t$如何操作。\n",
    "\n",
    "Goal: Maximize the long-time cumulative reward.\\\n",
    "目标：最大化长期累积的奖励。\n",
    "\n",
    "#### Sequential Decision Making\n",
    "\n",
    "Goal: Select actions to maximize future reward.\\\n",
    "目标：选择行动以最大化未来的奖励。\n",
    "\n",
    "Actions may have long term consequences.\\\n",
    "行动可能会产生长期的后果。\n",
    "\n",
    "Reward may be delayed.\\\n",
    "奖励可能会延迟。\n",
    "\n",
    "It may be better to sacrifice immediate reward to gain more long-term reward.\\\n",
    "为了获得更长期的奖励而牺牲眼前的奖励可能会更好。\n",
    "\n",
    "#### Designing reward functions\n",
    "\n",
    "In this course the reward function will often be given.\\\n",
    "在本课程中，通常会给定奖励函数。\n",
    "\n",
    "However, when RL is used in practice, the design of the rewards is very important:\\\n",
    "然而，当RL应用于实践时，奖励的设计就非常重要了:\n",
    "* It will determine what the agent tries to achieve,\\\n",
    "它将决定agent试图实现什么，\n",
    " * The agent may find unintended ways to increase the reward.\\\n",
    " agent可能会找到意想不到的方法来增加奖励。\n",
    "* It will influence how the agent learns.\\\n",
    "它将影响agent的学习方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a policy?\n",
    "\n",
    "Policy: Formally a distribution over actions given states\\\n",
    "策略：对给定状态的操作的分布\n",
    "$$\n",
    "\\pi(a|s) = P\\{A_t=a | S_t=s\\}\n",
    "$$\n",
    "\n",
    "A policy defines the agents behavior in different states.\\\n",
    "策略定义了不同状态下的agent行为。\n",
    "\n",
    "When the policy is deterministic, we sometimes write\\\n",
    "当策略是确定的时，我们有时会写\n",
    "$$\n",
    "a = \\pi(s)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
