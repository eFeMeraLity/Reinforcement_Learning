{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a process that has a value in each time period. Let $X_n$ denote its value in time period $n$, and suppose we want to make a probability model for the sequence of successive values $X_0,X_1,X_2,\\cdots$. The simplest model would probably be to assume that the $X_n$ are independent random variables, but often such an assumption is clearly unjustified.\\\n",
    "For instance, starting at some time suppose that $X_n$ represents the price of one share of some security, such as Google, at the end of $n$ additional trading days. Then it certainly seems unreasonable to suppose that the price at the end of day $n+1$ is independent of the prices on days $n,n−1,n−2$ and so on down to day 0. However, it might be reasonable to suppose that the price at the end of trading day $n+1$ depends on the previous end-of-day prices only through the price at the end of day $n$. That is, it might be reasonable to assume that the conditional distribution of $X_{n+1}$ given all the past end-of-day prices $X_n, X_{n−1}, \\cdots ,X_0$ depends on these past prices only through the price at the end of day $n$. Such an assumption defines a Markov chain, a type of stochastic process that will be studied in this chapter, and which we now formally define.\n",
    "\n",
    "Let $\\{X_n,n=0,1,2,\\cdots\\}$ be a stochastic process that takes on a finite or countable number of possible values. Unless otherwise mentioned, this set of possible values of the process will be denoted by the set of nonnegative integers $\\{0,1,2,\\cdots\\}$. If $X_n=i$, then the process is said to be in state $i$ at time $n$. We suppose that whenever the process is in state $i$, there is a fixed probability $P_{ij}$ that it will next be in state $j$. That is, we suppose that\\\n",
    "设$\\{X_n,n=0,1,2,\\cdots\\}$是一个随机过程，具有有限或可数的可能值。除非另有说明，此过程的可能值集将由非负整数$\\{0,1,2,\\cdots\\}$表示。如果$X_n=i$，则进程在$n$时刻处于$i$状态。我们假设当进程处于$i$状态时，下一个其进入$j$状态的概率$P_{ij}$是固定的。也就是说，我们假设\n",
    "\n",
    "$$\n",
    "P\\{X_{n+1}=j | X_n=i, X_{n-1}=i_{n-1}, \\cdots, X_1=i_1, X_0=i_0\\} = P_{ij}\n",
    "\\tag{4.1}\n",
    "\\label{eq:4.1}\n",
    "$$\n",
    "for all states $i_0, i_1, \\cdots, i_{n-1}, i, j$ and all $n \\geq 0$.\n",
    "\n",
    "Such a stochastic process is known as a **Markov chain**. Equation \\ref{eq:4.1} may be interpreted as stating that, for a Markov chain, the conditional distribution of any future state $X_{n+1}$, given the past states $X_0, X1, \\cdots, X_{n−1}$ and the present state $X_n$, is independent of the past states and depends only on the present state.\\\n",
    "这样的随机过程被称为**马尔科夫链**。式\\ref{eq:4.1}可以解释为：对于马尔科夫链，给定过去状态$X_0, X1, \\cdots, X_{n−1}$和当前状态$X_n$，任何未来状态$X_{n+1}$的条件分布与过去状态无关，仅依赖于当前状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Markov Decision Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a process that is observed at discrete time points to be in any one of $M$ possible states, which we number by $1, 2, \\cdots, M$. After observing the state of the process, an action must be chosen, and we let $A$, assumed finite, denote the set of all possible actions.\\\n",
    "考虑在离散时间点观察到的过程处于$M$可能状态中的任何一种，我们用$1, 2, \\cdots, M$编号。在观察过程的状态之后，必须选择一个动作，我们让$A$，假定是有限的，表示所有可能动作的集合。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
